package lexer

import (
	"bufio"
	"bytes"
	"fmt"
	"io"
	"strings"
)

const testVersion = 2

const (
	// NUM is tag for Numeric
	NUM int = (256 + iota)
	// OP is tag for Operator
	OP
	// ID is tag for Identifier (like variable, function name, keyword)
	ID
	// BOOL is tag for boolean value
	BOOL
)

// Token is the most basic unit of code
type Token struct {
	Tag   int
	Value interface{}
}

func (token Token) String() string {
	if token.Tag <= 255 {
		return string(byte(token.Tag))
	}
	return fmt.Sprintf("%v", token.Value)
}

// Lexer can scan a byte stream and output Tokens
type Lexer struct {
	stdin *bufio.Reader
	line  int
	token Token
}

// NewLexer creates a lexer for an io.Reader stream.
func NewLexer(rd io.Reader) *Lexer {
	return &Lexer{bufio.NewReader(rd), 0, Token{}}
}

// NewLexerForString creates a lexer for a string.
func NewLexerForString(input string) *Lexer {
	return NewLexer(strings.NewReader(input))
}

// Token returns the most recent token generated by a call to Scan.
func (lex *Lexer) Token() Token {
	return lex.token
}

// Scan advances the Scanner to the next token, which will then be
// available through the Token method. It returns false when the
// scan stops, either by reaching the end of the input or an error.
func (lex *Lexer) Scan() bool {
	var lookahead byte
	var err error

	// skipWhite
	for {
		lookahead, err = lex.stdin.ReadByte()
		if err == nil && isWhiteSpace(lookahead) {
			if lookahead == '\n' {
				lex.line++
			}
			continue
		}
		if err != nil {
			return false // usually means reach End Of Stream.
		}
		lex.stdin.UnreadByte()
		break
	}

	switch {
	case isDigit(lookahead) || lookahead == '.':
		lex.token = Token{NUM, lex.scanNUM()}
	case isLetter(lookahead) || lookahead == '_':
		value := lex.scanID()
		if value == "true" || value == "false" {
			lex.token = Token{BOOL, value == "true"}
		} else {
			lex.token = Token{ID, value}
		}
	case isOperator(lookahead):
		lex.token = Token{OP, lex.scanOP()}
	default:
		lex.stdin.ReadByte()
		lex.token = Token{int(lookahead), nil}
	}
	return true
}

func (lex *Lexer) scanNUM() float64 {
	value := float64(0.0)
	fmt.Fscan(lex.stdin, &value)
	return value
}

func (lex *Lexer) scanID() string {
	var buffer bytes.Buffer
	for {
		b, err := lex.stdin.ReadByte()
		if err == nil && (isLetter(b) || isDigit(b) || b == '_') {
			buffer.WriteByte(b)
			continue
		}
		if err == nil {
			lex.stdin.UnreadByte()
		}
		break
	}
	return buffer.String()
}

func (lex *Lexer) scanOP() string {
	b1, _ := lex.stdin.ReadByte()
	b2, err2 := lex.stdin.ReadByte()
	if err2 != nil {
		return string(b1)
	}
	if b2 == '=' && strings.ContainsAny("><=+-*/", string(b1)) ||
		b2 == b1 && strings.ContainsAny("+-&|", string(b1)) {
		return string([]byte{b1, b2})
	}
	lex.stdin.UnreadByte()
	return string(b1)
}

func isWhiteSpace(x byte) bool {
	return x == '\n' || x == '\t' || x == ' '
}

func isDigit(x byte) bool {
	return x >= '0' && x <= '9'
}

func isLetter(x byte) bool {
	return x >= 'a' && x <= 'z' || x >= 'A' && x <= 'Z'
}

func isOperator(x byte) bool {
	return strings.ContainsAny("><=+-*/&|", string(x))
}
